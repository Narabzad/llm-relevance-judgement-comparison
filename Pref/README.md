# Preference judgments (with gpt-4o)

These judgments are based on a sampling algorithm for human preference described in Charles L. A. Clarke, Alexandra Vtyurina, and Mark D. Smucker. Assessing top-k preferences. *ACM Transactions on Information Systems*. 2021. See: https://arxiv.org/abs/2007.11682 and https://github.com/claclark/preferences

The preference script (`pref.py`) was employed exactly as described in that repo except that GPT-4o was used in place of human judgements (`judge.py`).

Output files from the preference judgment process are found in subdirectories:
- `DL2019`: Full judgments for TREC Deep Learning 2019
- `DL2020`: Full judgments for TREC Deep Learning 2020
- `DL2021`: Full judgments for TREC Deep Learning 2021
- `ANTIQUE`: One round of judgments for the ANTIQUE collection.
We conducted only one round for ANTIQUE because ANTIQUE was not used in our experiments for agreement with system Rankings.

Files in these subdirectories can be understood as follows:
- `log.*` - raw logs from GPT-4o, include prompts and responses
- `judge.*`- preference judgment extracted from the corresponding `log.*` files
- `request.*` - preference requests generated by the sampling algorithm (see above)
- `state` - final judgment state of sampling algorithm (see above)

Sampling was based on **all** relevant documents, whereas human sampling is normally restricted to the top grades.  Computation of best vs. acceptable used the log.00 files, which are a random sample of all pairing following the algorithm above.  The `*.unacceptable` files separately judge a sample of relevant vs. non-relevant documents to measure alignment with human judgments.

Scripts:
- `agree.py`: Compute agreement statistics between TREC qrels and an LLM judgment log
- `human.py`: Compute agreement statistics between human preferences and a judgment log
- `judge.py`: Judgment script for LLM preferences (GPT-4o)
- `prefj.py`: Sampling algorithm (from https://github.com/claclark/preferences)
- `qrels.py`: Map graded qrels to binary qrels for use by `prefj.py` (see below)
- `reformat.py`: Reformat `judge.*` files into qrel format for use by compatibility measures
- `unacceptable.py`: Generate judgment requests to compare relevant (best/acceptable) vs. non-relevant (unacceptable)

Because human assessment is expensive, the sampling algorithm (`prefj.py`) normally operates on only the top grades. The `qrels.*` files in this directory are used to initialize the sampling algorithm with **all** relevant documents. They represent an intermediate step in the judgment process and are included only for completeness.

The `prefs.*` files are one output of the overall assessment process. They are generated from the `*.judge` files with `reformat.py` These files are used to compute compatibility measures reported in our paper. The scripts in the associated directory (../Compatibility) illustrate their use.

The following commands generate the human alignment data from the paper.
```
./agree.py ../data/qrels.dl19-passage.txt DL2019/log.00
./agree.py ../data/qrels.dl19-passage.txt DL2019/log.unacceptable
./agree.py ../data/qrels.dl20-passage.txt DL2020/log.00
./agree.py ../data/qrels.dl20-passage.txt DL2020/log.unacceptable
./agree.py ../data/qrels.dl21-passage.txt DL2021/log.00
./agree.py ../data/qrels.dl21-passage.txt DL2021/log.unacceptable
./agree.py --antique ../data/qrels.dlantique-passage.txt ANTIQUE/log.00

```

**Note:** Preference judgments normally require at least an initial binary relevance pass since preference judging a non-relevant item vs. another non-relevent item can't be expect to produce anything other than a arbitrary response or a tie. For this initial relevance pass, we choose to use the official qrels for these binary judgments (`qrels.*`). An alternative would be to use the LLM-based binary judgments. This choice represents a possible limitation of our experiments.
